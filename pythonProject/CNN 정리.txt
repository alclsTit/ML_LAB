1. CNN 
1) 정의 
- CNN은 합성곱 신경망이라 불리며 Convolutional Neural Networks의 약자로 이미지나 영상 데이터를 처리할 때 주로 사용합니다. 
합성곱이란 "CNN의 원본 이미지 픽셀과 커널이라고 불리는 필터간의 곱과 합으로 이루어진 값이 결과 픽셀 하나에 저장하는것을 의미"하며 
해당 작업이 전처리 작업이 들어가는 신경망 모델 

* 합성곱? CNN의 원본 이미지 픽셀과 커널이라고 불리는 필터간의 곱과 합으로 이루어진 값이 결과 픽셀 하나에 저장되므로 합성곱이라 표현 

2) CNN의 탄생 배경 
- CNN이 나오기 전 2차원 이미지에 대한 인식은 이를 1차원으로 flat 시켜 한줄 데이터로 만들어 신경망이 학습시키는 방법이었습니다. 
  이렇게 될 경우 이미지 정보가 손실되어 인접한 픽셀간의 상관관계가 무시되어 이미지 분류에 학습시간과 효율이 떨어졌습니다. 
  이러한 기존 신경망의 문제점과 
  이미지를 인식할 때 전체가 아닌 일부 범위 안에 존재하는 특징을 인식하여 해당 이미지가 무엇인지 판단한다는 아이디어에서 발생한 이론입니다. 

* 예를 들어, 새의 부리 모습만을 보고 해당 종이 무엇인지 판별하거나 
  공구 드라이버의 머리쪽 형태가 어떻게 되어있는지에 따라 해당 공구가 십자 드라이버인지, 일자 드라이버인지 판별할 수 있습니다.  

3) CNN의 작동원리 
- CNN의 작동 원리는 입력 값 이미지인 원본 이미지의 모든 영역을 지정한 간격(stride)으로 이동하면서 필터(커널)를 반복 합성곱하여 모든 채널의 합성곱의 합으로 결과이미지를 만드는 작업입니다. 
  이를 예를 들어 설명하면, 4X4 형태의 원본 이미지가 있고 3X3 형태의 커널 필터를 여기에 적용시키면 최종 결과로 2X2 형태의 이미지가 만들어집니다. 
  2X2의 이미지 한칸에 들어가는 값들은 원본 이미지 하나와 이에 대응된 커널 필터간의 행렬 곱이 저장됩니다. 

* 필터: 이미지를 찾아내기 위한 공용 파라미터 
* stride: 필터가 원본 이미지를 순회하는 간격의 크기 
* 결과 이미지의 가로, 세로 크기는 (원본 이미지 가로, 세로 크기 - 커널 필터 가로, 세로 크기 + 1) 이 됩니다. 

- 해당 이미지는 현재 커널 필터를 한칸 씩 이동했지만, 
  2칸 이상씩 이동할 수 도 있습니다. 이렇게 될 경우 결과 이미지는 더 작아지게 됩니다.

4) zero padding 
- 원본 이미지에 대한 Convolution 처리에 의해서 발생한 이미지 손실(해당 이미지 손실에 의해서 신경망 성능에 악영향이 발생)을 막기 위해서 
  원본 이미지 테두리에 0으로 된 값을 추가로 저장하여 커널 필터를 적용하여 이미지 손실을 없애는 방법   

- 장점
  1. 원본 이미지 테두리에 1만큼의 padding을 주어 0 값으로 채워 넣은 이미지에 커널 필터 적용 시 결과 이미지는 원본 이미지와 동일한 크기로 추출되며 
     이로써 이미지 손실이 발생하지 않는다 
 
  2. 원본 이미지의 2행 2열에 노란색 상자에 1과 같이 이미지에 중요한 요소가 들어있는 경우, 
     zero padding 을 진행하게 되면 padding을 하지 않았을 때보다 여러차례 지나가게 되므로 해당 정보를 충분히 이용할 수 있다. 
     예를 들어, 4페이지의 padding 하지 않았을 때의 원본 이미지는 커널 필터가 해당 모서리를 한번 훑고 지나갔지만 
     5페이지의 padding 진행을 하였을 땐 원본 이미지의 해당 모서리를 커널 필터가 4번 훑고 지나갔다.  


5) 네트워크 구조 
- 39 x 31 흑백 이미지에 대해서 CNN 모델을 적용하면 어떻게 되는지 순차적으로 설명해보겠습니다.

1. Convolution Layer 1
- 첫번째로 원본 이미지에 Convolution 을 적용하면, 출력 데이터 크기는 (36, 28, 20) 이 되고 학습 파라미터는 320개가 됩니다.
  출력 데이터는 입력 데이터에 필터를 적용한 값으로 (39 - 4 + 1, 31 - 4 + 1) 및 출력 채널을 적용하여 (36, 28, 20) 이 도출됩니다.
  학습 파라미터는 필터 x 입력채널 x 출력채널로 4 x 4 x 1 x 20 => 320 이 도출됩니다.

2. Max Pooling Layer 1
- Convolution Layer 1의 출력데이터인 (36, 28, 20) 가 MaxPooling의 입력데이터가 되고 (2,2) 크기인 MaxPooling을 적용하면 
  (18, 14, 20) 이 도출됩니다. Max Pooling에서의 학습 파라미터는 없습니다.

3. Convolution Layer 2
- Max Pooling Layer1의 출력 데이터를 입력 데이터로 하여 출력 데이터를 구하면, 
  (18, 14, 20) 에 (3,3) 필터를 적용하여 (16, 12, 40)의 출력 데이터를 도출한다. 
  학습 파라미터는 20 x 3 x 3 x 40 = 7200개 된다. 

4. Max Pooling Layer 2
- Convolution Layer2의 출력 데이터 (16, 12, 40) 에 Max Pooling (2,2) 적용 시 (8, 6, 40)의 출력 데이터가 도출되고 학습 파라미터는 0이다.

5. Convolution Layer 3
- Max Pooling Layer2의 출력 데이터 (8, 6, 40) 에 (3, 3) 필터 적용을 하면 (6, 4, 60)의 출력 데이터가 도출되고 
  학습 파라미터는 40 x 3 x 3 x 60 = 21600개가 된다

6. Max Pooling Layer 3
- Convolution Layer3의 출력 데이터 (6, 4, 60) 에 Max Pooling (2, 2) 적용 시 (3, 2, 60)의 출력 데이터가 도출되고 학습 파라미터는 0이다.

7. Convolution Layer 4
- Max Pooling Layer3의 출력 데이터인 (3, 2, 60) 에 (2, 2) 필터 적용을 하면 (2, 1, 80)의 출력 데이터가 도출되고 
  학습 파라미터는 60 x 2 x 2 x 80 = 19200개가 된다

8. Flatten Layer (Vectorization)
- 마지막 Convolution 과정에서 얻은 출력 데이터를 일자 형태의 데이터로 펼치는 작업 진행, (2, 1, 80) 입력 데이터가 2 x 1 x 80 = (160, 1) 으로 변환한다. 
  Flatten Layer에는 파라미터가 존재하지 않고 입력 데이터 크기만 변경한다.
* Fully Connected Neural Network = 이전 레이어의 모든 노드가 다음 레이어의 모든 노드에 연결된 레이어를 Fully Connected Layer라고 한다

9. Soft-max Layer 
- Flatten 입력 데이터인 (160, 1)에 최종 데이터인 분류 클래스 (100,1) 을 적용하면 Soft-max Layer의 학습 파라미터는 160,000개가 된다.
CNN의 총 학습 파라미터는 208,320개로 (320 + 7200 + 21,600 + 19,200 + 160,000의 합이다)